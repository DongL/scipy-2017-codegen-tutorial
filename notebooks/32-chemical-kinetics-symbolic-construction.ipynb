{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symbolic representation of chemical kinetics\n",
    "As we saw in the previous notebook, the rate of chemical reactions can be described by ordinary differential equations.\n",
    "\n",
    "In this notebook we will look at a classic example in chemical kinetics:\n",
    "[Robertson's example](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.53.8603).\n",
    "It is a 3-species reaction system:\n",
    "\n",
    "$$\n",
    "A \\overset{k_1}{\\rightarrow} B \\\\\n",
    "B + C \\overset{k_2}{\\rightarrow} A + C \\\\\n",
    "2 B \\overset{k_3}{\\rightarrow} B + C\n",
    "$$\n",
    "\n",
    "where A, B and C represent three different chemical species (e.g. reactive molecules dissolved in water). What is special about this system is that the numerical stepping needs to be performed using an implicit method (requiring the Jacobian) when solving for large time scales.\n",
    "\n",
    "The rate of each process follows the [law of mass action](https://en.wikipedia.org/wiki/Law_of_mass_action), i.e. the rate is proportional to the concentration of each reacting species (to the power of their multiplicity). The proportionality constant is known as the rate constant of the reaction ($k_1,\\ k_2\\ \\&\\ k_3$ in our case). If we denote the rate of each reaction:\n",
    "\n",
    "$$\n",
    "r_1 = k_1[A] \\\\\n",
    "r_2 = k_2[B][C] \\\\\n",
    "r_3 = k_3[B]^2\n",
    "$$\n",
    "\n",
    "$[A],\\ [B],\\ [C]$ denotes the concentration of respective species. We can now formulate a system of ordinary differential equations describing how the concentrations evolve over time:\n",
    "\n",
    "$$\n",
    "\\frac{d[A]}{dt} = r_2 - r_1 \\\\\n",
    "\\frac{d[B]}{dt} = r_1 - r_2 - r_3 \\\\\n",
    "\\frac{d[C]}{dt} = r_3\n",
    "$$\n",
    "\n",
    "We will now express these differential equations (and their Jacobian) symbolically using SymPy. We saw in the previous notebook how we can use matrices with integer coefficients to describe the system of ODEs. In practice, those matrices, will consist of mostly zeros. So dictionaries are a better suited data structure for serialization. Let us write a function to deserialize to SymPy expressions.\n",
    "\n",
    "We choose to describe Robertson's example above as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions = [\n",
    "    ('k1', {'A': 1}, {'B': 1, 'A': -1}),\n",
    "    ('k2', {'B': 1, 'C': 1}, {'A': 1, 'B': -1}),\n",
    "    ('k3', {'B': 2}, {'B': -1, 'C': 1})\n",
    "]\n",
    "names = 'A B C'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext scipy2017codegen.exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use either the ``%exercise`` or ``%load`` magic to get the exercise / solution respecitvely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../scipy2017codegen/symbolic_constr.py\n",
    "from operator import mul\n",
    "from functools import reduce\n",
    "import sympy as sym\n",
    "\n",
    "def prod(seq):\n",
    "    return reduce(mul, seq) if seq else 1\n",
    "\n",
    "def mk_exprs_symbs(rxns, names):\n",
    "    symbs = sym.symbols(names, real=True, nonnegative=True)\n",
    "    c = dict(zip(names, symbs))\n",
    "    f = {n: 0 for n in names}\n",
    "    k = []\n",
    "    for coeff, r_stoich, net_stoich in rxns:\n",
    "        k.append(sym.S(coeff))\n",
    "        r = k[-1]*prod([c[rk]**p for rk, p in r_stoich.items()])  # EXERCISE: c[rk]**p\n",
    "        for net_key, net_mult in net_stoich.items():\n",
    "            f[net_key] += net_mult*r  # EXERCISE: net_mult*r\n",
    "    return [f[n] for n in names], symbs, tuple(k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the above exercise you may want to remember what the law of mass action looks like from the previous notebook:\n",
    "\n",
    "$$\n",
    "\\frac{dc_i}{dt} = \\sum_j S_{ij} r_j \\\\\n",
    "r_j = k_j\\prod_l c_l^{R_{jl}}\n",
    "$$\n",
    "\n",
    "where $k_j$, S and R corresponds to ``coeff``, ``net_stoich`` and ``r_stoich`` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym.init_printing()\n",
    "ydot, y, k = mk_exprs_symbs(reactions, names)\n",
    "ydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\dot{\\mathbf{y}}$ now represent our ODE system, where $\\mathbf{y}$ is our state vector (concentrations). We will need a callback to evaluate $\\dot{\\mathbf{y}}$ when we integrate this ODE system numerically (using ``scipy.integrate.odeint``). As we have seen SymPy can provide us with this callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../scipy2017codegen/25_lambdify\n",
    "t = sym.symbols('t')  # not used in this case.\n",
    "f = sym.lambdify((y, t) + k, ydot)  # EXERCISE: (y, t) + k\n",
    "y, k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lambda function is needed to give f the signature asked for by ``odeint``. ``full_output=True`` makes odeint return a dictionary with information about the numerical integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tout = np.logspace(-6, 6)\n",
    "k_vals = (0.04, 1e4, 3e7)\n",
    "y0 = [1, 0, 0]\n",
    "yout, info = odeint(f, y0, tout, k_vals, full_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(tout, yout)\n",
    "plt.legend(names)\n",
    "print(\"The jacobian was evaluated %d times.\" % info['nje'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "If we look closer at the info-dictionary we will see that odeint (or rather LSODA which is the unerlying package) switched method from an explicit Adams method to an implicit Backward Differentiation Formula (BDF). It is common for chemical kinetics problems that the problem becomes stiff. The larger number of species, the bigger is the Jacobian matrix.\n",
    "\n",
    "By default the solver will approximate the elements in the Jacobian matrix by taking finite differences of $\\mathbf{f}$. This is often works quite satisfactorlily but for larger systems it sometimes fails. A more robust (and faster) approach is to provide a callback which evaluates an analytic Jacobian. Using SymPy we can do this quite effortlessly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = sym.Matrix(ydot).jacobian(y)\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_cb = sym.lambdify((y, t) + k, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yout, info = odeint(f, y0, tout, k_vals, full_output=True, Dfun=J_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(tout, yout)\n",
    "plt.legend(names)\n",
    "print(\"The jacobian was evaluated %d times.\" % info['nje'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the solver needed to evaluate the Jacobian fewer times (due to it being essentially exact this time around). For larger systems the impact of an analytic Jacobian is often even greater (being the difference between a failed and succuessul integration). \n",
    "\n",
    "Benchmarking with and without the analytic Jacobian callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit odeint(f, y0, tout, k_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit odeint(f, y0, tout, k_vals, Dfun=J_cb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
